FC16SSZwPT-v0:
  n_timesteps: 4_000_000
  n_envs: 32 # = size of rollout buffer / n_steps
  n_steps: 8192 # = size of rollout buffer / n_envs
  learning_rate: 0.0001 # weight of each update
  batch_size: 512 # number of steps to consider per update
  n_epochs: 10 # how often to process each rollout buffer
  ent_coef: 0.05 # entropy, exploration term
  policy: 'MlpPolicy'

Nakamoto-v0:
  n_timesteps: 4_000_000
  gamma: 1. # discount factor (no discount, we terminate on any path)
  n_envs: 24 # = size of rollout buffer / n_steps
  n_steps: 1024 # = size of rollout buffer / n_envs
  learning_rate: 0.0001 # weight of each update
  batch_size: 512 # number of steps to consider per update
  n_epochs: 10 # how often to process each rollout buffer
  ent_coef: 0.1 # entropy, exploration term
  policy: 'MlpPolicy'
