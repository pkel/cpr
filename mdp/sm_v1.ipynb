{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404b850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitcoin import Bitcoin\n",
    "from compiler import Compiler\n",
    "from parallel import Parallel\n",
    "from sm_v1 import Config, SelfishMining, StateEditor\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ba4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg(protocol, *args, alpha=0.25, gamma=0.5, truncate=5, horizon=0, **kwargs):\n",
    "    return Config(\n",
    "        protocol=protocol(*args, **kwargs),\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        truncate_on_pow=truncate,\n",
    "        horizon=horizon,\n",
    "    )\n",
    "\n",
    "\n",
    "def compile(*args, verbose=False, **kwargs):\n",
    "    config = cfg(*args, **kwargs)\n",
    "    se = StateEditor()\n",
    "    c = Compiler(SelfishMining(se, config))\n",
    "    while c.explore():\n",
    "        if verbose:\n",
    "            process = psutil.Process()\n",
    "            trace, _state = peek(c)\n",
    "            info = dict(\n",
    "                protocol=config.protocol.name,\n",
    "                n_states_explored=len(c.explored),\n",
    "                n_states_queued=c.queue.qsize(),\n",
    "                n_states_seen=len(c.state_map),\n",
    "                n_actions=len(c.action_map),\n",
    "                n_transitions=len(c.transitions),\n",
    "                trace_blocks_mined=trace.blocks_mined,\n",
    "                trace_actions_taken=trace.actions_taken,\n",
    "                ram_usage_gb=process.memory_info().rss / 1024**3,\n",
    "            )\n",
    "            info[\"queuing_factor\"] = info[\"n_states_queued\"] / info[\"n_states_explored\"]\n",
    "            pp.pprint(info)\n",
    "    return c.mdp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dba077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.05\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.01, 0.05, 0.1, 0.2, 0.3, 0.35, 0.4, 0.5]\n",
    "ptmdp = []\n",
    "mdp = []\n",
    "for a in alpha:\n",
    "    print(a)\n",
    "    ptmdp.append(compile(Bitcoin, alpha=a, gamma=0.5, truncate=5, horizon=100))\n",
    "    mdp.append(compile(Bitcoin, alpha=a, gamma=0.5, truncate=5, horizon=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384ee17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, *args, n_iter=100, discount=0.99, verbose=False):\n",
    "    value = np.zeros(mdp.n_states, dtype=float)\n",
    "    policy = np.zeros(mdp.n_states, dtype=int)\n",
    "\n",
    "    for iteration in range(n_iter):\n",
    "        value_next = np.zeros(mdp.n_states, dtype=float)\n",
    "        policy_next = np.zeros(mdp.n_states, dtype=int)\n",
    "\n",
    "        for src, actions in enumerate(mdp.tab):\n",
    "            best_v = 0.0\n",
    "            best_a = -1  # no action possible\n",
    "            for act, lst in actions.items():\n",
    "                if act < 0:\n",
    "                    continue\n",
    "                this_v = 0.0\n",
    "                for t in lst:\n",
    "                    this_v += t.probability * (\n",
    "                        t.reward + discount * value[t.destination]\n",
    "                    )\n",
    "                if this_v >= best_v:  # intentionally to not stick with action -1\n",
    "                    best_v = this_v\n",
    "                    best_a = act\n",
    "            value_next[src] = best_v\n",
    "            policy_next[src] = best_a\n",
    "            assert best_a >= 0 or len(actions) == 0\n",
    "\n",
    "        value_delta = np.abs(value_next - value).max()\n",
    "        policy_delta = (policy_next != policy).sum()\n",
    "        if verbose:\n",
    "            print(iteration, value[:5], value_delta, policy_delta)\n",
    "        value = value_next\n",
    "        policy = policy_next\n",
    "    return value, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f763e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8043"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp[0].n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e195c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_iteration(ptmdp[0], n_iter=500, discount=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d26c7f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: alpha=0.01\n",
      "1: alpha=0.05\n",
      "2: alpha=0.1\n",
      "3: alpha=0.2\n",
      "4: alpha=0.3\n",
      "5: alpha=0.35\n",
      "6: alpha=0.4\n",
      "7: alpha=0.5\n"
     ]
    }
   ],
   "source": [
    "policy = []\n",
    "ptvalue = []\n",
    "for i, m in enumerate(ptmdp):\n",
    "    print(f\"{i}: alpha={alpha[i]}\")\n",
    "    v, p = value_iteration(m, discount=1, n_iter=500)\n",
    "    policy.append(p)\n",
    "    ptvalue.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "931f4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.01 ptvalue[0:2]=[49.84483445 48.84483445] policy=[0 0 1 0 1 0 2 1 0 1] 43823 616\n",
      "alpha=0.05 ptvalue[0:2]=[84.19039387 83.19039387] policy=[0 0 1 0 1 0 2 1 0 1] 43957 2225\n",
      "alpha=0.1 ptvalue[0:2]=[91.97750223 90.97750223] policy=[0 0 1 0 1 0 2 1 0 1] 43957 2225\n",
      "alpha=0.2 ptvalue[0:2]=[96.37270019 95.37270019] policy=[0 0 1 0 1 0 2 1 0 1] 43957 2225\n",
      "alpha=0.3 ptvalue[0:2]=[97.86789465 96.86789465] policy=[0 0 1 0 1 0 2 1 0 1] 43965 3632\n",
      "alpha=0.35 ptvalue[0:2]=[98.27787726 97.27787726] policy=[0 0 1 0 1 0 2 1 0 1] 43965 3632\n",
      "alpha=0.4 ptvalue[0:2]=[98.57069763 97.57069763] policy=[0 0 1 0 1 0 2 1 0 1] 43993 686\n",
      "alpha=0.5 ptvalue[0:2]=[98.93970303 97.93970303] policy=[0 0 1 0 1 0 2 1 0 1] 43993 686\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(alpha)):\n",
    "    print(\n",
    "        f\"alpha={alpha[i]} ptvalue[0:2]={ptvalue[i][0:2]} policy={policy[i][:10]} {sum(policy[i])} {hash(policy[i].tobytes()) % 10000}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f1d33da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8043 8043 8043\n"
     ]
    }
   ],
   "source": [
    "print(mdp[0].n_states, ptmdp[0].n_states, len(policy[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eef9a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47418/3958891035.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  return reward / progress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.01 rpp[0:2]=[0.78853291 0.78630586]\n",
      "alpha=0.05 rpp[0:2]=[0.96232473 0.96023222]\n",
      "alpha=0.1 rpp[0:2]=[0.98356017 0.98151006]\n",
      "alpha=0.2 rpp[0:2]=[0.99376254 0.99173212]\n",
      "alpha=0.3 rpp[0:2]=[0.99699025 0.9949653 ]\n",
      "alpha=0.35 rpp[0:2]=[0.99785623 0.99583241]\n",
      "alpha=0.4 rpp[0:2]=[0.99847039 0.99644709]\n",
      "alpha=0.5 rpp[0:2]=[0.99924115 0.99721754]\n"
     ]
    }
   ],
   "source": [
    "def reward_per_progress_backpropagation(mdp, policy, n_iter=500):\n",
    "    reward = np.zeros(mdp.n_states, dtype=float)\n",
    "    progress = np.zeros(mdp.n_states, dtype=float)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        reward_next = np.zeros(mdp.n_states, dtype=float)\n",
    "        progress_next = np.zeros(mdp.n_states, dtype=float)\n",
    "        for src in range(mdp.n_states):\n",
    "            act = policy[src]\n",
    "            if act == -1:\n",
    "                assert len(mdp.tab[src]) == 0\n",
    "                continue\n",
    "            for t in mdp.tab[src][act]:\n",
    "                reward_next[src] += t.probability * (t.reward + reward[t.destination])\n",
    "                progress_next[src] += t.probability * (\n",
    "                    t.progress + progress[t.destination]\n",
    "                )\n",
    "        reward = reward_next\n",
    "        progress = progress_next\n",
    "    return reward / progress\n",
    "\n",
    "\n",
    "for i in range(len(alpha)):\n",
    "    rpp = reward_per_progress_backpropagation(mdp[i], policy[i])\n",
    "    print(f\"alpha={alpha[i]} rpp[0:2]={rpp[0:2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
