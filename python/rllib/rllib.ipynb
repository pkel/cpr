{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5f8b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local-v0.5.1-4-g837f00d'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 18:49:48,093\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.15', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '100.111.83.80', 'raylet_ip_address': '100.111.83.80', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-16_18-49-46_464390_2204225/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-16_18-49-46_464390_2204225/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-16_18-49-46_464390_2204225', 'metrics_export_port': 57677, 'gcs_address': '100.111.83.80:62857', 'address': '100.111.83.80:62857', 'dashboard_agent_listen_port': 52365, 'node_id': '40b85291856ba9808e7c6c27aefd0be1c6d72b98c59c2463d382517b'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import psutil\n",
    "import ray\n",
    "from ray.rllib.algorithms import ppo\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import cpr_gym\n",
    "\n",
    "display(cpr_gym.engine.cpr_lib_version)\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff05decf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 18:49:49,216\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-11-16 18:49:49,218\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    }
   ],
   "source": [
    "def sparse_relative(\n",
    "    protocol=\"nakamoto\", protocol_args={}, alpha=1 / 3, gamma=0.5, episode_len=128\n",
    "):\n",
    "    protocol_fn = getattr(cpr_gym.protocols, protocol)\n",
    "    env = gym.make(\n",
    "        \"cpr_gym:core-v0\",\n",
    "        proto=protocol_fn(**protocol_args),\n",
    "        max_steps=episode_len,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        defenders=math.ceil((1 - alpha) / (1 - gamma)),\n",
    "    )\n",
    "    env = cpr_gym.wrappers.SparseRelativeRewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "register_env(\"sparse_relative\", lambda config: sparse_relative(**config))\n",
    "\n",
    "\n",
    "def sparse_per_progress(\n",
    "    protocol=\"nakamoto\", protocol_args={}, alpha=1 / 3, gamma=0.5, episode_len=128\n",
    "):\n",
    "    protocol_fn = getattr(cpr_gym.protocols, protocol)\n",
    "    env = gym.make(\n",
    "        \"cpr_gym:core-v0\",\n",
    "        proto=protocol_fn(**protocol_args),\n",
    "        max_steps=episode_len,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        defenders=math.ceil((1 - alpha) / (1 - gamma)),\n",
    "    )\n",
    "    env = cpr_gym.wrappers.SparseRewardPerProgressWrapper(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "register_env(\"sparse_per_progress\", lambda config: sparse_per_progress(**config))\n",
    "\n",
    "\n",
    "def dense_per_progress(\n",
    "    protocol=\"nakamoto\", protocol_args={}, alpha=1 / 3, gamma=0.5, episode_len=128\n",
    "):\n",
    "    protocol_fn = getattr(cpr_gym.protocols, protocol)\n",
    "    env = gym.make(\n",
    "        \"cpr_gym:core-v0\",\n",
    "        proto=protocol_fn(**protocol_args),\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        defenders=math.ceil((1 - alpha) / (1 - gamma)),\n",
    "    )\n",
    "    env = cpr_gym.wrappers.DenseRewardPerProgressWrapper(env, episode_len=episode_len)\n",
    "    return env\n",
    "\n",
    "\n",
    "register_env(\"dense_per_progress\", lambda config: dense_per_progress(**config))\n",
    "\n",
    "algo = ppo.PPO(\n",
    "    env=\"sparse_relative\",\n",
    "    config=dict(\n",
    "        env_config=dict(\n",
    "            protocol=\"nakamoto\",\n",
    "            protocol_args=dict(),\n",
    "            alpha=0.45,\n",
    "            gamma=0.5,\n",
    "            episode_len=128,\n",
    "        ),\n",
    "        framework=\"torch\",\n",
    "        num_gpus=0,\n",
    "        num_workers=-1,\n",
    "        model=dict(\n",
    "            fcnet_hiddens=[32, 32, 32],\n",
    "            fcnet_activation=\"relu\",\n",
    "        ),\n",
    "        rollout_fragment_length=2048,\n",
    "        train_batch_size=2048 * 6,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# for i in range(10):\n",
    "# print(i)\n",
    "# algo.train()\n",
    "\n",
    "# algo.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df1ef6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from ray import air, tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "# From https://docs.ray.io/en/latest/tune/examples/pbt_ppo_example.html\n",
    "\n",
    "# Postprocess the perturbed config to ensure it's still valid\n",
    "def explore(config):\n",
    "    # ensure we collect enough timesteps to do sgd\n",
    "    if config[\"train_batch_size\"] < config[\"sgd_minibatch_size\"] * 2:\n",
    "        config[\"train_batch_size\"] = config[\"sgd_minibatch_size\"] * 2\n",
    "    # ensure we run at least one sgd iter\n",
    "    if config[\"num_sgd_iter\"] < 1:\n",
    "        config[\"num_sgd_iter\"] = 1\n",
    "    return config\n",
    "\n",
    "\n",
    "pbt = PopulationBasedTraining(\n",
    "    time_attr=\"time_total_s\",\n",
    "    perturbation_interval=120,\n",
    "    resample_probability=0.25,\n",
    "    # Specifies the mutations of these hyperparams\n",
    "    hyperparam_mutations={\n",
    "        \"lambda\": lambda: random.uniform(0.9, 1.0),\n",
    "        \"clip_param\": lambda: random.uniform(0.01, 0.5),\n",
    "        \"lr\": lambda: 10 ** (-random.uniform(2.5, 5)),\n",
    "        \"num_sgd_iter\": lambda: random.randint(1, 30),\n",
    "        \"sgd_minibatch_size\": lambda: random.randint(128, 16384),\n",
    "        \"train_batch_size\": lambda: random.randint(2000, 160000),\n",
    "    },\n",
    "    custom_explore_fn=explore,\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"episode_reward_mean\",\n",
    "        mode=\"max\",\n",
    "        scheduler=pbt,\n",
    "        num_samples=-1,\n",
    "        # max_concurrent_trials=6,\n",
    "        # reuse_actors=True,\n",
    "    ),\n",
    "    param_space={\n",
    "        \"env\": \"sparse_relative\",\n",
    "        \"env_config\": dict(\n",
    "            protocol=\"nakamoto\",\n",
    "            protocol_args=dict(),\n",
    "            alpha=0.45,\n",
    "            gamma=0.5,\n",
    "            episode_len=128,\n",
    "        ),\n",
    "        \"framework\": \"torch\",\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 11,\n",
    "        \"model\": dict(\n",
    "            fcnet_hiddens=[32, 32, 32],\n",
    "            fcnet_activation=\"relu\",\n",
    "        ),\n",
    "        \"kl_coeff\": 1.0,\n",
    "        # These params are tuned from a fixed starting value.\n",
    "        \"lambda\": 0.95,\n",
    "        \"clip_param\": 0.2,\n",
    "        \"lr\": 1e-3,\n",
    "        \"train_batch_size\": 10000,\n",
    "        # These params start off randomly drawn from a set.\n",
    "        \"num_sgd_iter\": tune.choice([10, 20, 30]),\n",
    "        \"sgd_minibatch_size\": tune.choice([128, 256, 512, 1024, 2048]),\n",
    "    },\n",
    ")\n",
    "# results = tuner.fit()\n",
    "\n",
    "# print(\"best hyperparameters: \", results.get_best_result().config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd3e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "from ray import air, tune\n",
    "from ray.tune.search.skopt import SkOptSearch\n",
    "\n",
    "# From https://docs.ray.io/en/latest/tune/examples/pbt_ppo_example.html\n",
    "\n",
    "bayesopt = SkOptSearch(\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "base_config = {\n",
    "    \"env\": \"sparse_relative\",\n",
    "    \"env_config\": dict(\n",
    "        protocol=\"nakamoto\",\n",
    "        protocol_args=dict(),\n",
    "        alpha=0.45,\n",
    "        gamma=0.5,\n",
    "        episode_len=128,\n",
    "    ),\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 0,\n",
    "    \"num_workers\": -1,\n",
    "    \"model\": dict(\n",
    "        fcnet_hiddens=[32, 32, 32],\n",
    "        fcnet_activation=\"relu\",\n",
    "    ),\n",
    "    \"evaluation_duration\": 64,\n",
    "}\n",
    "\n",
    "\n",
    "def my_ppo(config={}):\n",
    "    config = config | base_config\n",
    "\n",
    "    budget = config.pop(\"time_budget_s\", 300)\n",
    "\n",
    "    sms = config.get(\"sgd_minibatch_size\", 128)\n",
    "    tbsm = config.pop(\"train_batch_size_multiple\", 1)\n",
    "    tbs = sms * tbsm\n",
    "    config[\"train_batch_size\"] = tbs\n",
    "    config[\"rollout_fragment_length\"] = config[\"train_batch_size\"]\n",
    "\n",
    "    ed = config.get(\"evaluation_duration\", 1)\n",
    "    config[\"evaluation_duration_unit\"] = \"episodes\"\n",
    "    # it does something really weird instead of counting episodes ...\n",
    "    config[\"evaluation_duration\"] = max(\n",
    "        1, int(ed / tbsm / (sms / config[\"env_config\"][\"episode_len\"]))\n",
    "    )\n",
    "\n",
    "    # config[\"evaluation_duration\"] = max(1, int(ed / tbsm))\n",
    "\n",
    "    env = config.pop(\"env\", \"sparse_relative\")\n",
    "\n",
    "    algo = ppo.PPO(env=env, config=config)\n",
    "\n",
    "    res = algo.train()\n",
    "    while res[\"time_total_s\"] < budget:\n",
    "        res = algo.train()\n",
    "\n",
    "    return algo.evaluate()[\"evaluation\"]\n",
    "\n",
    "\n",
    "# my_ppo(dict(train_batch_size_multiple = 2, time_budget_s = 10, sgd_minibatch_size=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df77394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_samples: 288'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 26\u001b[0m\n\u001b[1;32m      7\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[1;32m      8\u001b[0m     my_ppo,\n\u001b[1;32m      9\u001b[0m     tune_config\u001b[38;5;241m=\u001b[39mtune\u001b[38;5;241m.\u001b[39mTuneConfig(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     },\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#results = tuner.fit()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest hyperparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mget_best_result(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconfig)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "tune_budget_h = 2\n",
    "run_budget_s = 300\n",
    "cores = 12\n",
    "num_samples = int(tune_budget_h * 60 * 60 / run_budget_s * cores)\n",
    "display(f\"num_samples: {num_samples}\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    my_ppo,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=bayesopt,\n",
    "        num_samples=num_samples,\n",
    "    ),\n",
    "    param_space={\n",
    "        \"time_budget_s\": run_budget_s,\n",
    "        \"kl_coeff\": tune.uniform(0, 1.0),\n",
    "        \"lambda\": tune.uniform(0.9, 1.0),\n",
    "        \"clip_param\": tune.uniform(0.01, 0.5),\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"num_sgd_iter\": tune.randint(1, 30),\n",
    "        \"sgd_minibatch_size\": tune.choice([128, 256, 512, 1024, 2048, 4096]),\n",
    "        \"train_batch_size_multiple\": tune.choice([1, 2, 4, 8]),\n",
    "    },\n",
    ")\n",
    "# results = tuner.fit()\n",
    "\n",
    "print(\n",
    "    \"best hyperparameters: \",\n",
    "    results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\").config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
